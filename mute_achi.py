import subprocess
from faster_whisper import WhisperModel
import re
import os

VIDEO_FILE = "Untitled_longer.mov"
AUDIO_FILE = "audio.wav"
OUTPUT_FILE = "output.mp4"
KEYWORD = "××—×™"
MUTE_PADDING = 0.1  # ×©× ×™×•×ª ×œ×¤× ×™ ×•××—×¨×™

def normalize(word: str) -> str:
    word = word.lower()
    word = re.sub(r'[^\u0590-\u05EA]', '', word)
    word = word.replace('×š', '×›').replace('×', '×').replace('×Ÿ', '× ').replace('×£', '×¤').replace('×¥', '×¦')
    return word

print("ğŸ§ Extracting audio...")
subprocess.run(["ffmpeg", "-y", "-i", VIDEO_FILE, "-q:a", "0", "-map", "a", AUDIO_FILE])

print("ğŸ§  Transcribing...")
model = WhisperModel("medium", compute_type="auto")
segments, _ = model.transcribe(AUDIO_FILE, language="he", word_timestamps=True)

mute_ranges = []
for segment in segments:
    for word in segment.words:
        if normalize(word.word) == KEYWORD:
            start = max(0, word.start - MUTE_PADDING)
            end = word.end + MUTE_PADDING
            mute_ranges.append((start, end))

if not mute_ranges:
    print("âœ… No '××—×™' found.")
    exit()

print(f"ğŸ”‡ Found {len(mute_ranges)} '××—×™' to mute. Ranges:")
for i, (start, end) in enumerate(mute_ranges):
    print(f"  {i+1}: {start:.2f}s â†’ {end:.2f}s")

# Create volume filter complex
volume_filter = []
for i, (start, end) in enumerate(mute_ranges):
    volume_filter.append(f"volume=0:enable='between(t,{start},{end})'")

# Combine all volume filters
volume_filter_str = ",".join(volume_filter)

print("ğŸ”Š Applying mute filters...")
subprocess.run([
    "ffmpeg", "-y",
    "-i", VIDEO_FILE,
    "-af", volume_filter_str,
    "-c:v", "copy",
    OUTPUT_FILE
])

# × ×™×§×•×™
if os.path.exists(AUDIO_FILE):
    os.remove(AUDIO_FILE)

print(f"âœ… Final video saved as: {OUTPUT_FILE}")
